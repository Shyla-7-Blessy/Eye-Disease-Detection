# -*- coding: utf-8 -*-
"""eye_disease_main (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mnB2fxWY2EeQ-KOJRBo6B6A2JGLBqB0t
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow  as tf

dataset=tf.keras.preprocessing.image_dataset_from_directory("/content/drive/MyDrive/ROFT")

ds_train=tf.keras.preprocessing.image_dataset_from_directory(
    "/content/drive/MyDrive/ROFT",
    validation_split=0.2,
    subset="training",  # Add subset="training" for ds_train
    seed=123
)

ds_validation=tf.keras.preprocessing.image_dataset_from_directory(
    "/content/drive/MyDrive/ROFT",
    validation_split=0.2,
    subset="validation",
    seed=123
)

import tensorflow_datasets

import tensorflow_datasets

# Load a dataset using tensorflow_datasets.load
dataset = tensorflow_datasets.load('mnist')

import tensorflow_datasets

# Load a dataset using tensorflow_datasets.load
dataset = tensorflow_datasets.load('mnist', as_supervised=True) #Loads the dataset in a tuple format

# Get information about the dataset
info = tensorflow_datasets.builder('mnist').info

# Access the class names through the dataset info object
class_names = info.features['label'].names
print(class_names)

import tensorflow as tf

size = (512, 512)

def resize_image(image, label):
  """Resizes the image to the specified size.

  Args:
    image: The image tensor.
    label: The image label.

  Returns:
    A tuple containing the resized image and label.
  """
  resized_image = tf.image.resize(image, size)
  return resized_image, label

# Apply the resize_image function to each element in the dataset
ds_train = ds_train.map(lambda x, y: resize_image(x, y))
ds_val = ds_validation.map(lambda x, y: resize_image(x, y))

import matplotlib.pyplot as plt

plt.figure(figsize=(10,10))
for images,labels in ds_train.take(1):
  for i in range(9):
    ax=plt.subplot(3,3,i+1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

from tensorflow.keras.models import Sequential
from tensorflow.keras import layers

image=Sequential(
    [
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(height_factor=(-0.2,-0.3),width_factor=(0.2,0.3),interpolation="bilinear"),
    layers.RandomContrast(factor=0.1),
    layers.RandomTranslation(height_factor=0.1,width_factor=0.1),
  ],
    name="image",
)

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

for images, labels in ds_train.take(1):
    plt.figure(figsize=(10, 10))
    first_image = images[0]

    def f(x):
        return int(x)  # Use the built-in int instead of np.int

    f2 = np.vectorize(f)

    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)

        # Generate augmented image inside the loop for each subplot:
        augmented_image = image(tf.expand_dims(first_image, 0), training=True)

        plt.imshow(augmented_image[0].numpy().astype("int32"))
        plt.title(f2(labels[0]))
        plt.axis("off")

import os
import random
import shutil

# Base directory containing all images
base_dir = '/content/drive/MyDrive/ROFT/OD_Fundus'  # Replace with the actual path

# Define split directories inside a new "dataset" directory
dataset_dir = '/content/drive/MyDrive/ROFT/OD_Fundus'
train_dir = os.path.join(dataset_dir, 'train')
val_dir = os.path.join(dataset_dir, 'val')
test_dir = os.path.join(dataset_dir, 'test')

# Create these directories if they don't exist
os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

# Get a list of all image files in the base directory
all_images = [f for f in os.listdir(base_dir) if os.path.isfile(os.path.join(base_dir, f))]
random.shuffle(all_images)  # Shuffle images for randomness

# Define the split ratios
train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# Calculate the number of images for each split
num_images = len(all_images)
train_count = int(num_images * train_ratio)
val_count = int(num_images * val_ratio)

# Split the data
train_images = all_images[:train_count]
val_images = all_images[train_count:train_count + val_count]
test_images = all_images[train_count + val_count:]

def move_images(image_list, source_dir, dest_dir):
    for image in image_list:
        shutil.move(os.path.join(source_dir, image), os.path.join(dest_dir, image))

# Move the images
move_images(train_images, base_dir, train_dir)
move_images(val_images, base_dir, val_dir)
move_images(test_images, base_dir, test_dir)

print("Training images:", len(os.listdir(train_dir)))
print("Validation images:", len(os.listdir(val_dir)))
print("Testing images:", len(os.listdir(test_dir)))

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# Corrected path to your dataset
train_dir = '/content/drive/MyDrive/ROFT'

# Check if directory exists
if not os.path.exists(train_dir):
    raise FileNotFoundError(f"Directory not found: {train_dir}")

# Define image data generator with validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Load training data
train_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

# Load validation data
val_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

"""# **EyeDeepNet Model for Classification**"""

pip install tensorflow

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping

# Image dimensions and batch size
IMG_HEIGHT, IMG_WIDTH = 224, 224
BATCH_SIZE = 32

# ✅ Correct dataset path
dataset_path = '/content/drive/MyDrive/ROFT/OD_Fundus'

# ✅ ImageDataGenerator with validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

# ✅ Use subset='training'
train_data = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

# ✅ Use same directory with subset='validation'
val_data = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# ✅ EyeDeepNet Model
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    MaxPooling2D(2, 2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(train_data.num_classes, activation='softmax')  # Number of classes auto-detected
])

# Compile model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
history = model.fit(
    train_data,
    epochs=3,
    validation_data=val_data,
    callbacks=[EarlyStopping(patience=3, restore_best_weights=True)]
)

# Evaluate model
val_loss, val_accuracy = model.evaluate(val_data)
print(f"Validation Accuracy: {val_accuracy * 100:.2f}%")

import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model

# ✅ Load the trained model
# Skip this if model is already in memory
# model = load_model('eyedeepnet_model.h5')  # Save earlier if needed

# ✅ Define class labels (automatically detected during training)
class_labels = list(train_data.class_indices.keys())

# ✅ Directory with test images
test_dir = '/content/drive/MyDrive/ROFT/OD_Fundus'  # Path to folder with images
image_files = []

# Collect 5–10 image paths from subfolders
for class_name in os.listdir(test_dir):
    class_path = os.path.join(test_dir, class_name)
    if os.path.isdir(class_path):
        for img_file in os.listdir(class_path)[:2]:  # Take 2 per class
            image_files.append(os.path.join(class_path, img_file))

# ✅ Predict for each image
for img_path in image_files:
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    prediction = model.predict(img_array)
    predicted_class_index = np.argmax(prediction)
    confidence = np.max(prediction)

    predicted_class = class_labels[predicted_class_index]

    # Show image and prediction
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Predicted: {predicted_class} ({confidence*100:.2f}%)")
    plt.show()

"""**RetinaNet Model for Object Detection**"""

!pip install keras-retinanet

!wget https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5 -P pretrained_models/

!retinanet-convert-model snapshots/resnet50_csv_03.h5 /content/retina_model.h5

import os

img_dir = '/content/drive/MyDrive/ROFT/OD_Fundus'
print(os.listdir(img_dir))

img_path = '/content/drive/MyDrive/ROFT/OD_Fundus/Normal/image1.jpg'

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import os

# ✅ Define your class labels in correct order (according to training)
class_labels = ['Glaucoma', 'Diabetic Retinopathy', 'AMD']

# ✅ Folder with test images (OD_Fundus contains subfolders)
img_dir = '/content/drive/MyDrive/ROFT/OD_Fundus'
image_paths = []

# Collect 5–10 images from all subfolders
for subfolder in os.listdir(img_dir):
    subfolder_path = os.path.join(img_dir, subfolder)
    if os.path.isdir(subfolder_path):
        for img_name in os.listdir(subfolder_path)[:3]:  # take 3 from each class
            img_path = os.path.join(subfolder_path, img_name)
            if img_path.lower().endswith(('.jpg', '.png', '.jpeg')):
                image_paths.append(img_path)
    if len(image_paths) >= 10:
        break

# ✅ Loop through images and predict
for img_path in image_paths:
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    prediction = model.predict(img_array)
    predicted_index = np.argmax(prediction)
    predicted_class = class_labels[predicted_index]
    confidence = np.max(prediction)

    # ✅ Display result
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"{os.path.basename(img_path)}\nPrediction: {predicted_class} ({confidence*100:.2f}%)")
    plt.show()

    # ✅ Print to console
    print(f"🧠 {os.path.basename(img_path)} ➜ Predicted Disease: {predicted_class} ({confidence*100:.2f}%)\n")

"""**U-Net Model for Segmentation**"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
import os

# ✅ Step 1: Build a MobileNet-based model (fast, no training)
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False  # Freeze the base

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(3, activation='softmax')(x)  # 3 classes: Glaucoma, DR, AMD

model = Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# ⚠️ Model is untrained — will give random predictions (you said no training)

# ✅ Step 2: Class labels in training order
class_labels = ['Glaucoma', 'Diabetic Retinopathy', 'AMD']

# ✅ Step 3: Load images from folders
img_dir = '/content/drive/MyDrive/ROFT/OD_Fundus'
image_paths = []

# Get 2–3 images from each subfolder
for subfolder in os.listdir(img_dir):
    subfolder_path = os.path.join(img_dir, subfolder)
    if os.path.isdir(subfolder_path):
        for img_name in os.listdir(subfolder_path)[:2]:
            img_path = os.path.join(subfolder_path, img_name)
            if img_path.lower().endswith(('.jpg', '.png', '.jpeg')):
                image_paths.append(img_path)
    if len(image_paths) >= 10:
        break

# ✅ Step 4: Predict on each image
for img_path in image_paths:
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    prediction = model.predict(img_array)[0]  # shape: (3,)
    predicted_index = np.argmax(prediction)
    predicted_class = class_labels[predicted_index]
    confidence = np.max(prediction)

    plt.imshow(img)
    plt.axis('off')
    plt.title(f"{os.path.basename(img_path)}\nPrediction: {predicted_class} ({confidence*100:.2f}%)")
    plt.show()

    print(f"🧠 {os.path.basename(img_path)} ➜ Predicted Disease: {predicted_class} ({confidence*100:.2f}%)\n")

!pip install gradio --quiet

import gradio as gr
import numpy as np
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.preprocessing import image
from PIL import Image

# Load untrained MobileNetV2 (placeholder, no epochs)
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(3, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

class_labels = ['Glaucoma', 'Diabetic Retinopathy', 'AMD']

# Disease info
disease_info = {
    'Glaucoma': {
        "description": "A condition that damages the eye's optic nerve.",
        "symptoms": "Eye pain, blurred vision, halos around lights.",
        "medications": "Latanoprost, Timolol",
        "suggestions": "Regular eye exams, avoid eye strain."
    },
    'Diabetic Retinopathy': {
        "description": "Complication of diabetes affecting blood vessels in the retina.",
        "symptoms": "Spots or dark strings (floaters), blurred vision.",
        "medications": "Ranibizumab, Aflibercept",
        "suggestions": "Control blood sugar, regular retinal exams."
    },
    'AMD': {
        "description": "Age-related Macular Degeneration, affects central vision.",
        "symptoms": "Distorted vision, difficulty reading or recognizing faces.",
        "medications": "AREDS2 supplements, Anti-VEGF injections",
        "suggestions": "Healthy diet, no smoking, wear sunglasses."
    }
}

# Prediction logic
def analyze_image(img: Image.Image):
    img = img.resize((224, 224))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    preds = model.predict(img_array)[0]
    pred_idx = np.argmax(preds)
    disease = class_labels[pred_idx]
    confidence = preds[pred_idx]

    info = disease_info[disease]
    report = f"""
## 🧠 Detected Disease: **{disease}**
**Confidence:** {confidence*100:.2f}%

**📄 Description:**
{info['description']}

**👁️ Symptoms:**
{info['symptoms']}

**💊 Medications:**
{info['medications']}

**✅ Suggestions:**
{info['suggestions']}
"""
    return report

# UI blocks like LlamaCoder
with gr.Blocks(title="Reti-Revive | AI Eye Disease Detection") as demo:
    gr.Markdown("## 🧪 Reti-Revive Eye Disease Detector")
    gr.Markdown("Upload an eye image and click **Analyze** to receive a detailed diagnosis report.")

    with gr.Row():
        with gr.Column():
            img_input = gr.Image(type="pil", label="Upload Fundus Image")
            analyze_btn = gr.Button("🩺 Analyze Image")
        with gr.Column():
            report_output = gr.Markdown(label="Diagnosis Report")

    analyze_btn.click(fn=analyze_image, inputs=img_input, outputs=report_output)

demo.launch(share=True)

